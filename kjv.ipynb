{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Anastasia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Anastasia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# I'm a python beginner, I'm sure much of this is ugly and bad\n",
    "\n",
    "import nltk, logging\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import word2vec\n",
    "from string import punctuation\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "stop_words = set(stopwords.words('english'))\n",
    "%config InlineBackend.figure_format = 'svg' \n",
    "# imports, downloads, config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open and read file\n",
    "f = open(r\"kjv.txt\",\"r\")\n",
    "raw=f.read()\n",
    "#tokenize into sentences\n",
    "sents = nltk.sent_tokenize(raw)\n",
    "\n",
    "#tokenize sentences into words, make everything lowercase, remove punctuation\n",
    "for idx in range(len(sents)):\n",
    "     sents[idx]=nltk.word_tokenize(sents[idx])\n",
    "     sents[idx]=[w.lower() for w in sents[idx] if w not in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-03-17 11:27:35,806 : INFO : collecting all words and their counts\n",
      "2018-03-17 11:27:35,808 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2018-03-17 11:27:35,890 : INFO : PROGRESS: at sentence #10000, processed 295574 words, keeping 7051 word types\n",
      "2018-03-17 11:27:35,950 : INFO : PROGRESS: at sentence #20000, processed 537265 words, keeping 10156 word types\n",
      "2018-03-17 11:27:35,995 : INFO : collected 12564 word types from a corpus of 792640 raw words and 29887 sentences\n",
      "2018-03-17 11:27:35,996 : INFO : Loading a fresh vocabulary\n",
      "2018-03-17 11:27:36,019 : INFO : min_count=5 retains 5287 unique words (42% of original 12564, drops 7277)\n",
      "2018-03-17 11:27:36,020 : INFO : min_count=5 leaves 779815 word corpus (98% of original 792640, drops 12825)\n",
      "2018-03-17 11:27:36,050 : INFO : deleting the raw counts dictionary of 12564 items\n",
      "2018-03-17 11:27:36,051 : INFO : sample=0.001 downsamples 57 most-common words\n",
      "2018-03-17 11:27:36,052 : INFO : downsampling leaves estimated 515160 word corpus (66.1% of prior 779815)\n",
      "2018-03-17 11:27:36,086 : INFO : estimated required memory for 5287 words and 300 dimensions: 15332300 bytes\n",
      "2018-03-17 11:27:36,087 : INFO : resetting layer weights\n",
      "2018-03-17 11:27:36,184 : INFO : training model with 8 workers on 5287 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2018-03-17 11:27:36,774 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-03-17 11:27:36,777 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-03-17 11:27:36,781 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-03-17 11:27:36,785 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-03-17 11:27:36,792 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-17 11:27:36,804 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-17 11:27:36,814 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-17 11:27:36,818 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-17 11:27:36,819 : INFO : EPOCH - 1 : training on 792640 raw words (514580 effective words) took 0.6s, 826163 effective words/s\n",
      "2018-03-17 11:27:37,424 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-03-17 11:27:37,437 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-03-17 11:27:37,454 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-03-17 11:27:37,464 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-03-17 11:27:37,476 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-17 11:27:37,489 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-17 11:27:37,505 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-17 11:27:37,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-17 11:27:37,512 : INFO : EPOCH - 2 : training on 792640 raw words (515424 effective words) took 0.7s, 763568 effective words/s\n",
      "2018-03-17 11:27:38,139 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-03-17 11:27:38,140 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-03-17 11:27:38,141 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-03-17 11:27:38,147 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-03-17 11:27:38,150 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-17 11:27:38,169 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-17 11:27:38,172 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-17 11:27:38,181 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-17 11:27:38,181 : INFO : EPOCH - 3 : training on 792640 raw words (514790 effective words) took 0.6s, 797933 effective words/s\n",
      "2018-03-17 11:27:38,783 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-03-17 11:27:38,786 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-03-17 11:27:38,792 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-03-17 11:27:38,804 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-03-17 11:27:38,821 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-17 11:27:38,823 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-17 11:27:38,826 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-17 11:27:38,842 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-17 11:27:38,843 : INFO : EPOCH - 4 : training on 792640 raw words (515026 effective words) took 0.6s, 797498 effective words/s\n",
      "2018-03-17 11:27:39,459 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2018-03-17 11:27:39,460 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2018-03-17 11:27:39,463 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2018-03-17 11:27:39,476 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2018-03-17 11:27:39,480 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2018-03-17 11:27:39,497 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2018-03-17 11:27:39,499 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2018-03-17 11:27:39,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2018-03-17 11:27:39,514 : INFO : EPOCH - 5 : training on 792640 raw words (515291 effective words) took 0.6s, 797055 effective words/s\n",
      "2018-03-17 11:27:39,515 : INFO : training on a 3963200 raw words (2575111 effective words) took 3.3s, 773196 effective words/s\n",
      "2018-03-17 11:27:39,536 : INFO : saving Word2Vec object under bible_word2vec_gensim, separately None\n",
      "2018-03-17 11:27:39,537 : INFO : not storing attribute vectors_norm\n",
      "2018-03-17 11:27:39,539 : INFO : not storing attribute cum_table\n",
      "2018-03-17 11:27:39,722 : INFO : saved bible_word2vec_gensim\n",
      "2018-03-17 11:27:39,723 : INFO : storing vocabulary in bible_word2vec_vocabulary\n",
      "2018-03-17 11:27:39,751 : INFO : storing 5287x300 projection weights into bible_word2vec_org\n"
     ]
    }
   ],
   "source": [
    "# train and save the model\n",
    "bible_kjv_word2vec_model = word2vec.Word2Vec(sents, min_count=5, size=300, workers=8)\n",
    "bible_kjv_word2vec_model.save(\"bible_word2vec_gensim\")\n",
    "bible_kjv_word2vec_model.wv.save_word2vec_format(\"bible_word2vec_org\", \"bible_word2vec_vocabulary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tree', 1.7302131652832031),\n",
       " ('famine', 1.667422890663147),\n",
       " ('other', 1.667339563369751),\n",
       " ('therein', 1.6453050374984741),\n",
       " ('darkness', 1.6346666812896729),\n",
       " ('some', 1.586122989654541),\n",
       " ('sun', 1.553690791130066),\n",
       " ('morning', 1.551240086555481),\n",
       " ('water', 1.5495328903198242),\n",
       " ('much', 1.5250635147094727)]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: higher number = more similar, 0= unrelated, more negative number = more dissimilar\n",
    "# also, these numbers are based on the *context* in which the words appear, based on their distance from each other in the text\n",
    "bible_kjv_word2vec_model.wv.most_similar_cosmul(positive=['man'],negative=['father'])\n",
    "# words that are similar to \"man\" and dissimilar to \"father\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('jesus', 1.5076894760131836),\n",
       " ('jacob', 1.5040464401245117),\n",
       " ('abraham', 1.474555492401123),\n",
       " ('moses', 1.4744971990585327),\n",
       " ('saying', 1.4515154361724854),\n",
       " ('concerning', 1.4467947483062744),\n",
       " ('zippor', 1.377807855606079),\n",
       " ('word', 1.3763395547866821),\n",
       " ('david', 1.374647855758667),\n",
       " ('voice', 1.36969792842865)]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_kjv_word2vec_model.wv.most_similar_cosmul(positive=['man'],negative=['beast'])\n",
    "# words that are similar to \"man\" and dissimilar to \"beast\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pence', 2.135866641998291),\n",
       " ('tree', 1.917260766029358),\n",
       " ('lion', 1.8448923826217651),\n",
       " ('beast', 1.6707090139389038),\n",
       " ('stone', 1.6626919507980347),\n",
       " ('bottomless', 1.6529412269592285),\n",
       " ('dash', 1.6490983963012695),\n",
       " ('prey', 1.6477878093719482),\n",
       " ('little', 1.620700716972351),\n",
       " ('water', 1.609275221824646)]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_kjv_word2vec_model.wv.most_similar_cosmul(positive=['man'],negative=['christ'])\n",
    "# words that are similar to \"man\" and dissimilar to \"christ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('pence', 1.8520288467407227),\n",
       " ('tree', 1.7025773525238037),\n",
       " ('having', 1.6985000371932983),\n",
       " ('ten', 1.6900837421417236),\n",
       " ('lion', 1.6781864166259766),\n",
       " ('five', 1.6326961517333984),\n",
       " ('or', 1.615265965461731),\n",
       " ('sacrificeth', 1.6084561347961426),\n",
       " ('one', 1.5849075317382812),\n",
       " ('linen', 1.5843855142593384)]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_kjv_word2vec_model.wv.most_similar_cosmul(positive=['man'],negative=['god'])\n",
    "# words that are similar to \"man\" and dissimilar to \"god\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('truth', 0.7215267419815063),\n",
       " ('spirit', 0.7178041338920593),\n",
       " ('salvation', 0.7163286209106445),\n",
       " ('christ', 0.6995464563369751),\n",
       " ('hosts', 0.691597044467926),\n",
       " ('grace', 0.6898941993713379),\n",
       " ('glory', 0.6888221502304077),\n",
       " ('judgment', 0.6876793503761292),\n",
       " ('lord', 0.6869611144065857),\n",
       " ('righteousness', 0.6827335953712463)]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bible_kjv_word2vec_model.wv.most_similar_cosmul(positive=['god', 'fear'])\n",
    "# words that are similar to \"god\" and \"fear\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
